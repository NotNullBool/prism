[metadata]
name = prism-ds
description = The easiest way to create data pipelines in Python.
long_description_content_type = text/markdown
long_description = file: README.md
version = 0.1.7rc3
author = prism founders
author_email = hello@runprism.com
license = Apache-2.0
license_file = LICENSE
platforms = unix, linux, osx, win32
classifiers =
    Programming Language :: Python :: 3
    Programming Language :: Python :: 3.7
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
project_urls =
    homepage = https://www.runprism.com
    documentation = https://docs.runprism.com
    repository = https://github.com/runprism/prism

[options]
packages=find_namespace:
include_package_data=True
install_requires =
    astor>=0.7
    boto3>=1
    botocore>=1
    click>=8
    networkx>=2
    numpy>=1
    pandas>=1
    PyYAML>=6
    requests>=2    
    Jinja2==2.11.3            # for compatibility with dbt
    MarkupSafe<2.1,>=0.23     # for compatibility with Jinja2 version
    coolname>=2.2
    shortuuid>=1.0
python_requires = >=3.7
zip_safe = no

[options.extras_require]
snowflake = 
    snowflake-connector-python>=2
    pyarrow<10.1.0,>=10.0.1
bigquery =
    google-api-python-client>=2
    google-auth>=2
    google-cloud-bigquery>=2
    db-dtypes>=1
redshift =
    psycopg2-binary>=2.9
postgres = 
    psycopg2-binary>=2.9
trino =
    trino>=0.319
pyspark =
    pyspark>=3
dbt =
    dbt-core>=1
testing =
    snowflake-connector-python>=2
    pyarrow<8.1.0,>=8.0.0
    google-api-python-client>=2
    google-auth>=2
    google-cloud-bigquery>=2
    db-dtypes>=1
    psycopg2-binary>=2.9
    pyspark>=3
    dbt-core>=1
    dbt-snowflake>=1
    pytest>=7
    fastparquet>=0.8,<1
    tox>=3.24
    trino>=0.319


[options.entry_points]
console_scripts = 
    prism = prism.main:main


[flake8]
ignore = E124, E128
per-file-ignores = 
    prism/cli/init.py: W605
    prism/spark/script.py: F401, E201, E202, F821
    prism/logging.py: F821
    prism/templates/*: E501
max-line-length = 88
count = true
