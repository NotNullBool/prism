[metadata]
name = prism-ds
description = The easiest way to create data pipelines in Python.
long_description_content_type = text/markdown
long_description = file: README.md
version = 0.1.5-alpha
author = prism founders
author_email = hello@runprism.com
license = Apache-2.0
license_file = LICENSE
platforms = unix, linux, osx, win32
classifiers =
    Programming Language :: Python :: 3
    Programming Language :: Python :: 3.7
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
project_urls =
    homepage = https://www.runprism.com
    documentation = https://docs.runprism.com
    repository = https://github.com/runprism/prism

[options]
packages=find_namespace:
include_package_data=True
install_requires =
    astor>=0.7
    boto3>=1
    botocore>=1
    click>=8
    networkx>=2
    numpy>=1
    pandas>=1
    PyYAML>=6
    requests>=2    
    Jinja2==2.11.3            # for compatibility with dbt
    MarkupSafe<2.1,>=0.23     # for compatibility with Jinja2 version
python_requires = >=3.7
zip_safe = no

[options.extras_require]
snowflake = 
    snowflake-connector-python>=2
    pyarrow<8.1.0,>=8.0.0; extra == "pandas"
bigquery =
    pyarrow<8.1.0,>=8.0.0; extra == "pandas"     # for potential compatibility with snowflake
    google-api-python-client>=2
    google-auth>=2
    google-cloud-bigquery>=2
    db-dtypes>=1
redshift =
    psycopg2>=2.9
pyspark =
    pyspark>=3
dbt =
    dbt-core>=1
testing =
    snowflake-connector-python>=2
    pyarrow<8.1.0,>=8.0.0; extra == "pandas"
    google-api-python-client>=2
    google-auth>=2
    google-cloud-bigquery>=2
    db-dtypes>=1
    psycopg2>=2.9
    pyspark>=3
    dbt-core>=1
    dbt-snowflake>=1
    nose>=1
    fastparquet>=0.8,<1
    tox>=3.24


[options.entry_points]
console_scripts = 
    prism = prism.main:main
